{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#!/usr/bin/env python\n",
    "# coding: utf-8\n",
    "\n",
    "\"\"\"\n",
    "NAPLS3 BIDS Converter\n",
    "\n",
    "High-level Overview:\n",
    "1) Extract subject IDs and session information (dates â†’ session numbers)\n",
    "   from folder names in a 'source_images' directory.\n",
    "2) Unzip DICOMs (from .tgz archives) into an intermediate folder in\n",
    "   /scratch/ to avoid filesystem overload with small files.\n",
    "3) Convert DICOMs to NIfTI using dcm2niix.\n",
    "4) Move resulting .nii.gz (and .json) files into their proper BIDS format\n",
    "   folders (anat, func, dwi, fmap, etc.) within designated site-specific\n",
    "   directories.\n",
    "5) Provide additional utility and debugging functions to facilitate\n",
    "   working with metadata (e.g., IntendedFor, EchoTimes, TaskNames, etc.).\n",
    "\"\"\"\n",
    "\n",
    "import os\n",
    "import subprocess\n",
    "import tarfile\n",
    "import shutil\n",
    "import sys\n",
    "from datetime import datetime, timedelta\n",
    "import json\n",
    "import logging\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import re\n",
    "from collections import defaultdict, Counter\n",
    "import pprint\n",
    "from pathlib import Path\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# CONSTANTS & PATHS\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "# # Source data (folders with .nii.gz)\n",
    "source_images = \"/projects/f_ah1491_1/open_data/NAPLS3/sourcedata/image03\"\n",
    "\n",
    "# # BIDS directories\n",
    "bids_directory = '/projects/f_ah1491_1/open_data/NAPLS3/bidsdata'\n",
    "dicom_directory = '/scratch/kj537'\n",
    "\n",
    "\n",
    "# # Create the main BIDS directory if it doesn't already exist\n",
    "# if not os.path.exists(bids_directory):\n",
    "#     os.makedirs(bids_directory, exist_ok=True)\n",
    "#     print(f\"Created bids_directory at {bids_directory}\")\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# PERSONALIZED FUNCTIONS: Extract subject IDs, dates and mode \n",
    "#      !! Change based on your dataset !!\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def return_subject_id_given_session_id(session_id):\n",
    "    \"\"\"\n",
    "    This function works based on parsing the string for underscores and taking the \n",
    "    first unit, becuase that's where subject IDs were for my files. You'll have to change\n",
    "    this based on where subject IDs are for your files. They may be in the filename or \n",
    "    the associated JSON.\n",
    "\n",
    "\n",
    "    Given a session_id string (e.g., \"01S0300_2023-07-01\"), extract the subject ID.\n",
    "    Example:\n",
    "        session_id = \"01S0300_2023-07-01\" \n",
    "        subject_id = \"01S0300\"\n",
    "    \"\"\"\n",
    "    session_id_parts = session_id.split('_')\n",
    "    if len(session_id_parts) == 3:\n",
    "        subject_id = session_id_parts[0] + session_id_parts[1]\n",
    "        return subject_id\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "def return_date_given_filename(session_id):\n",
    "    \"\"\"\n",
    "    Attempt to extract a date or datetime from the file name using \n",
    "    multiple regex patterns. Returns a datetime object if found, else None.\n",
    "    \"\"\"\n",
    "    patterns = [\n",
    "        r'\\d{8}',         # YYYYMMDD\n",
    "        r'\\d{6}',         # YYYYMM\n",
    "        r'\\d{10,14}',     # YYYYMMDDHHMM, YYYYMMDDHHMMSS\n",
    "        r'\\d{4}-\\d{2}-\\d{2}',  # YYYY-MM-DD\n",
    "        r'\\d{2}-\\d{4}'    # MM-YYYY\n",
    "    ]\n",
    "    \n",
    "    for pattern in patterns:\n",
    "        matches = re.findall(pattern, session_id)\n",
    "        for match in matches:\n",
    "            try:\n",
    "                # Attempt to parse the string as various date formats\n",
    "                if len(match) == 6:\n",
    "                    return datetime.strptime(match, \"%Y%m\"), \"%Y%m\"\n",
    "                elif len(match) == 8:\n",
    "                    return datetime.strptime(match, \"%Y%m%d\"), \"%Y%m%d\"\n",
    "                elif len(match) == 10:\n",
    "                    if '-' in match:\n",
    "                        return datetime.strptime(match, \"%Y-%m-%d\"), \"%Y-%m-%d\"\n",
    "                    else:\n",
    "                        return datetime.strptime(match[:10], \"%Y%m%d%H\"), \"%Y%m%d%H\"\n",
    "                elif len(match) == 12:\n",
    "                    return datetime.strptime(match, \"%Y%m%d%H%M\"), \"%Y%m%d%H%M\"\n",
    "                elif len(match) == 14:\n",
    "                    return datetime.strptime(match, \"%Y%m%d%H%M%S\"), \"%Y%m%d%H%M%S\"\n",
    "            except ValueError:\n",
    "                continue\n",
    "    return None\n",
    "\n",
    "\n",
    "def find_mode(file_name): # this may also be a folder name after unzipping\n",
    "    \"\"\"\n",
    "    Given a file name, guess the scanning mode (anat, func, dwi, fmap).\n",
    "    If your filenames have mode information in them, !!change the strings!! \n",
    "    to adapt to your dataset.\n",
    "\n",
    "    If your filenames don't have mode markers, you'll have to extract information\n",
    "    from the JSONs. \n",
    "    \"\"\"\n",
    "    file_name = file_name.lower()\n",
    "    if \"fieldmap\" in file_name:\n",
    "        return \"fmap\"\n",
    "    elif \"bold\" in file_name:\n",
    "        return \"func\"\n",
    "    elif \"t1\" in file_name or \"t2\" in file_name or \"flash\" in file_name or \"flash2d\" in file_name:\n",
    "        return \"anat\"\n",
    "    elif \"diff\" in file_name:\n",
    "        return \"dwi\"\n",
    "    else:\n",
    "        return \"UnrecognizedFileType\"\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# CREATE SUBJECT-SESSIONS DICTIONARY\n",
    "#   These functions parse folder names and file dates to build a \n",
    "#   structure of subjects, their sessions, and the associated dates.\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "def create_subject_sessions_dict2(source_images, time_threshold):\n",
    "    \"\"\"\n",
    "    A second variant that does a two-pass approach:\n",
    "      1) Gather folder info (subject, date).\n",
    "      2) Add any files discovered to the relevant session if\n",
    "         dates are within time_threshold days. (Handles if \n",
    "         different scan-types are done on different days)\n",
    "\n",
    "    source_images = your directory where unzipped .nii.gz images are\n",
    "    time_threshold = an integer \n",
    "    \"\"\"\n",
    "    subject_sessions = {}\n",
    "\n",
    "    # First pass: Gather folder info\n",
    "    for subject_folder in os.listdir(source_images):\n",
    "        folder_path = os.path.join(source_images, subject_folder)\n",
    "        if os.path.isdir(folder_path):\n",
    "            parts = subject_folder.split('_')\n",
    "            subject_id = return_subject_id_given_session_id(subject_folder)\n",
    "            session_date, date_format = return_date_given_filename(subject_folder)\n",
    "            if isinstance(session_date, datetime): \n",
    "                session_info = (subject_id, \"1\", session_date, subject_folder)\n",
    "            \n",
    "                if subject_id in subject_sessions:\n",
    "                    subject_sessions[subject_id].append(session_info)\n",
    "                else:\n",
    "                    subject_sessions[subject_id] = [session_info]\n",
    "            else:\n",
    "                print(f\"Ignoring folder {subject_folder} as the date extracted was not a datetime variable\")\n",
    "        else:\n",
    "            print(f\"Ignoring folder {subject_folder} as it is not a folder\")\n",
    "    \n",
    "    # Second pass: Check file dates to see if a session already exists within 50 days\n",
    "    for dirpath, _, filenames in os.walk(source_images):\n",
    "        relative_path = os.path.relpath(dirpath, source_images)\n",
    "        first_subdir = relative_path.split(os.sep)[0] if os.sep in relative_path else \"\"\n",
    "        \n",
    "        for file in filenames:\n",
    "            if file.endswith('.nii.gz') or file.endswith('.json'):\n",
    "                session_parts = first_subdir.split('_')\n",
    "                if len(session_parts) > 2:\n",
    "                    subject_id = session_parts[0] + session_parts[1]\n",
    "                    file_date, date_format = return_date_given_filename(subject_folder)\n",
    "                    if file_date is None:\n",
    "                        continue\n",
    "\n",
    "                    # Convert file_date to datetime\n",
    "                    if isinstance(file_date, datetime):\n",
    "                        \n",
    "                        # Attach new session if none found within 50 days\n",
    "                        if subject_id in subject_sessions:\n",
    "                            sessions = subject_sessions[subject_id]\n",
    "                            found_session = False\n",
    "                            for i, (sess_sub_id, _, sess_date, _) in enumerate(sessions):\n",
    "                                if abs(sess_date - file_date) <= timedelta(days=time_threshold):\n",
    "                                    found_session = True\n",
    "                                    break\n",
    "                            if not found_session:\n",
    "                                subject_sessions[subject_id].append((subject_id, \"1\", file_date, file))\n",
    "        \n",
    "    # Sort sessions by date and assign session_nums\n",
    "    for sessions in subject_sessions.values():\n",
    "        sessions.sort(key=lambda x: x[2])\n",
    "        for i, session in enumerate(sessions):\n",
    "            sessions[i] = session[:1] + (str(i + 1),) + session[2:]\n",
    "    return subject_sessions\n",
    "\n",
    "\n",
    "def extract_ses_given_session_id(subject_sessions, session_id):\n",
    "    \"\"\"\n",
    "    Return the session number (e.g., '1') for a given session_id \n",
    "    by searching in subject_sessions dictionary.\n",
    "    \"\"\"\n",
    "    for key, sublist in subject_sessions.items():\n",
    "        for item in sublist:\n",
    "            if item[3] == session_id:\n",
    "                return item[1]\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_id_given_session_id(subject_sessions, session_id):\n",
    "    \"\"\"\n",
    "    Return the subject ID for a given session_id \n",
    "    by searching in subject_sessions dictionary.\n",
    "    \"\"\"\n",
    "    for key, sublist in subject_sessions.items():\n",
    "        for item in sublist:\n",
    "            if item[3] == session_id:\n",
    "                return key\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_subject_ids(subject_sessions):\n",
    "    \"\"\"\n",
    "    Return a list of all subject IDs from the subject_sessions dictionary.\n",
    "    \"\"\"\n",
    "    subject_ids = []\n",
    "    for subject_id, _ in subject_sessions.items():\n",
    "        subject_ids.append(subject_id)\n",
    "    return subject_ids \n",
    "\n",
    "\n",
    "def extract_session_ids(subject_sessions):\n",
    "    \"\"\"\n",
    "    Return a list of all session folder names from the subject_sessions dictionary.\n",
    "    \"\"\"\n",
    "    session_ids = []\n",
    "    for _, sublist in subject_sessions.items():\n",
    "        for item in sublist:\n",
    "            session_ids.append(item[3])\n",
    "    return session_ids\n",
    "\n",
    "\n",
    "def extract_session_nums(subject_sessions):\n",
    "    \"\"\"\n",
    "    Return a list of all session numbers (e.g. '1', '2') from the subject_sessions dictionary.\n",
    "    \"\"\"\n",
    "    session_nums = []\n",
    "    for _, sublist in subject_sessions.items():\n",
    "        for item in sublist:\n",
    "            session_nums.append(item[1])\n",
    "    return session_nums\n",
    "\n",
    "\n",
    "def extract_date_given_sub_ses(subject_sessions, subject_id, session_num):\n",
    "    \"\"\"\n",
    "    Given a subject and session number, return the associated date object/string.\n",
    "    \"\"\"\n",
    "    for key, sublist in subject_sessions.items(): \n",
    "        if key == subject_id:\n",
    "            for item in sublist:\n",
    "                if item[1] == session_num:\n",
    "                    # item = (subject_id, session_num, date, folder)\n",
    "                    return item[2]\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_ses_given_date(subject_sessions, filename):\n",
    "    \"\"\"\n",
    "    For a given subject and date, find the session number if a session\n",
    "    date is within 50 days of the file_date.\n",
    "    \"\"\"\n",
    "    file_date, date_format = return_date_given_filename(filename)\n",
    "    subject_id = return_subject_id_given_session_id(filename)\n",
    "    if isinstance(file_date, str):\n",
    "        # Attempt to parse the file_date string\n",
    "        try:\n",
    "            file_date_obj = datetime.strptime(file_date, date_format)\n",
    "        except ValueError:\n",
    "            return f\"Error: '{file_date}' is not a valid date string.\"\n",
    "    elif isinstance(file_date, datetime):\n",
    "        file_date_obj = file_date\n",
    "    else:\n",
    "        return f\"Error: {file_date} is not a str or datetime\"\n",
    "\n",
    "    # Check the difference\n",
    "    if file_date_obj:\n",
    "        if subject_id in subject_sessions:\n",
    "            for item in subject_sessions[subject_id]:\n",
    "                date = item[2]\n",
    "                if isinstance(date, str):\n",
    "                    try:\n",
    "                        session_date = datetime.strptime(date, date_format)\n",
    "                    except ValueError:\n",
    "                        return f\"Error: '{date}' is not a valid date string.\"\n",
    "                else:\n",
    "                    session_date = date\n",
    "\n",
    "                delta = abs(session_date - file_date_obj)\n",
    "                # 50 days tolerance\n",
    "                if delta <= timedelta(days=50):\n",
    "                    return item[1]\n",
    "        return f\"Error: no sessions found within 90 days for {subject_id}, file_date {file_date_obj}\"\n",
    "    return None\n",
    "\n",
    "\n",
    "def extract_dates_given_sub(subject_sessions, subject_id):\n",
    "    \"\"\"\n",
    "    For a given subject, return a list of session dates (as strings or datetime).\n",
    "    \"\"\"\n",
    "    datelist = []\n",
    "    for key, sublist in subject_sessions.items(): \n",
    "        if key == subject_id:\n",
    "            for item in sublist:\n",
    "                folder_name = item[3]\n",
    "                id_parts = folder_name.split('_')\n",
    "                date_str = id_parts[-1]\n",
    "                try:\n",
    "                    date_obj = datetime.strptime(date_str, \"%Y-%m-%d\")\n",
    "                    datelist.append(date_obj)\n",
    "                except ValueError as e:\n",
    "                    datelist.append(date_str)\n",
    "    return datelist\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# BIDS FOLDER CREATION & FILE MOVE FUNCTIONS\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "def create_subject_folder(subject_id):\n",
    "    \"\"\"\n",
    "    Create the top-level sub-XXX folder for a subject in the BIDS directory.\n",
    "    \"\"\"\n",
    "    subject_folder = os.path.join(bids_directory, f\"sub-{subject_id}\")\n",
    "    if not os.path.exists(subject_folder):\n",
    "        os.makedirs(subject_folder, exist_ok=True)\n",
    "\n",
    "        \n",
    "def create_session_folder(session_id, subject_sessions):\n",
    "    \"\"\"\n",
    "    Creates the BIDS session folder structure for a given session ID.\n",
    "\n",
    "    Example folder structure:\n",
    "      sub-<subject_id>/\n",
    "        ses-<session_num>/\n",
    "          anat/\n",
    "          func/\n",
    "          fmap/\n",
    "          dwi/\n",
    "    \"\"\"\n",
    "    directories = [\"anat\", \"func\", \"fmap\", \"dwi\"]\n",
    "    session_num = extract_ses_given_session_id(subject_sessions, session_id)\n",
    "    subject_id = extract_id_given_session_id(subject_sessions, session_id)\n",
    "    \n",
    "    session_path = os.path.join(bids_directory, f\"sub-{subject_id}\", f\"ses-{session_num}\")\n",
    "    for directory in directories:\n",
    "        os.makedirs(os.path.join(session_path, directory), exist_ok=True)\n",
    "\n",
    "\n",
    "\n",
    "def copy_file_with_new_name(filepath, destination_dir, new_filename):\n",
    "    \"\"\"\n",
    "    Copy a file from filepath to destination_dir with a new name (new_filename).\n",
    "\n",
    "    Returns a message indicating success, existence, or error.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        os.makedirs(destination_dir, exist_ok=True)\n",
    "        dest_file = os.path.join(destination_dir, new_filename)\n",
    "        if os.path.isfile(filepath):\n",
    "            if not os.path.isdir(dest_file):\n",
    "                if not os.path.exists(dest_file):\n",
    "                    shutil.copy2(filepath, dest_file)\n",
    "                    if os.path.isfile(os.path.join(destination_dir, new_filename)):\n",
    "                        return f\"{new_filename} confirmed move\"\n",
    "                else:\n",
    "                    return f\"{new_filename} already exists, skipping\"\n",
    "            else:\n",
    "                return f\"DESTINATION FILEPATH IS A DIRECTORY {dest_file}\"\n",
    "        else:\n",
    "            return \"SOURCE FILEPATH DOES NOT EXIST\"\n",
    "    except FileNotFoundError:\n",
    "        return \"THE SOURCE FILE NOT FOUND.\"\n",
    "    except PermissionError:\n",
    "        return f\"PERMISSION DENIED {dest_file}\"\n",
    "    except Exception as e:\n",
    "        return f\"ERROR OCCURRED: {e}\"\n",
    "\n",
    "\n",
    "def copy_file_to_bids(subject_id, session_num, file, filepath, bids_directory, parent_folder):\n",
    "    \"\"\"\n",
    "    Move or copy a file into the correct BIDS folder (anat/func/fmap/dwi).\n",
    "    The 'mode' is determined from either the file itself or the parent folder.\n",
    "    \"\"\"\n",
    "    mode = find_mode(file)\n",
    "    if mode == 'UnrecognizedFileType':\n",
    "        # If the file name doesn't clarify, check the parent folder\n",
    "        mode = find_mode(parent_folder)\n",
    "    \n",
    "    if mode != 'UnrecognizedFileType':\n",
    "        destination_dir = os.path.join(\n",
    "            bids_directory, f\"sub-{subject_id}\", f\"ses-{session_num}\", mode\n",
    "        )\n",
    "    else:\n",
    "        print(f\"Mode cannot be found for {file}\")\n",
    "        return\n",
    "    \n",
    "    try:\n",
    "        os.makedirs(destination_dir, exist_ok=True)\n",
    "        dest_file = os.path.join(destination_dir, file)\n",
    "        if os.path.isfile(filepath):\n",
    "            if not os.path.isdir(dest_file):\n",
    "                if not os.path.exists(dest_file):\n",
    "                    shutil.copy2(filepath, dest_file)\n",
    "                    if os.path.isfile(os.path.join(destination_dir, file)):\n",
    "                        print(f\"{file} confirmed move\")\n",
    "                    else:\n",
    "                        print(f\"{file} attempted to be moved but was not successful\")\n",
    "                else:\n",
    "                    print(f\"{file} already exists, can't be moved to {destination_dir}\")\n",
    "            else:\n",
    "                print(f\"Is directory: {dest_file}\")\n",
    "    except Exception as e:\n",
    "        print(f\"Error: {e} from moving {file} to {dest_file}\")\n",
    "\n",
    "\n",
    "def is_folder_empty(folder_path):\n",
    "    \"\"\"Check if a folder is empty.\"\"\"\n",
    "    return len(os.listdir(folder_path)) == 0    \n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# DICOM UNZIP & CONVERSION\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def unzip_and_convert_dicom(source_images, dicom_directory):\n",
    "    \"\"\"\n",
    "    1) Unzip .tgz DICOM folders into /scratch/subject_id.\n",
    "    2) Convert them to NIfTI with dcm2niix.\n",
    "    3) Remove the DICOMs to reduce clutter.\n",
    "    \"\"\"\n",
    "    for file in os.listdir(source_images):\n",
    "        filepath = os.path.join(source_images, file)\n",
    "        subject_id = return_subject_id_given_session_id(file)\n",
    "        mode = find_mode(file)\n",
    "        if file.endswith('.tgz'):\n",
    "            dcms_folder = os.path.join(dicom_directory, subject_id, os.path.basename(filepath).split('.')[0])\n",
    "            nii_folder = os.path.join(source_images, subject_id, os.path.basename(filepath).split('.')[0])\n",
    "            if not os.path.exists(nii_folder) or is_folder_empty(nii_folder):\n",
    "                os.makedirs(nii_folder, exist_ok=True)\n",
    "                \n",
    "                if not os.path.exists(dcms_folder):\n",
    "                    os.makedirs(dcms_folder, exist_ok=True)\n",
    "                with tarfile.open(filepath, 'r:gz') as tar:\n",
    "                    tar.extractall(dcms_folder)\n",
    "                    # Convert DICOMs\n",
    "                    subprocess.run([\n",
    "                        'dcm2niix', \n",
    "                        '-z', 'y',            # Compress as .nii.gz\n",
    "                        '-f', '%s_%b',        # Output filename format\n",
    "                        '-o', nii_folder,     # Output folder\n",
    "                        dcms_folder\n",
    "                    ])\n",
    "                    # Remove the DICOM folder after conversion\n",
    "                    os.system(f'rm -r {dcms_folder}')\n",
    "                print(f\"Unzipped/converted dicoms for subject {subject_id} in session folder {source_images}\")\n",
    "\n",
    "\n",
    "def find_delete_substring(original_string, substring):\n",
    "    \"\"\"\n",
    "    Return a string with the specified substring removed.\n",
    "    \"\"\"\n",
    "    index = original_string.find(substring)\n",
    "    if index == -1:\n",
    "        return original_string\n",
    "    return original_string.replace(substring, '')\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# DATE & FILENAME UTILITIES\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def date_conversion(date_string, date_format):\n",
    "    \"\"\"\n",
    "    Safely convert a date string of format YYYY-MM-DD into a datetime object.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        date_object = datetime.strptime(date_string, date_format)\n",
    "        return date_object\n",
    "    except ValueError as e:\n",
    "        print(f\"{date_string} couldn't be datetime'd: {e}\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# METADATA GATHERING & RUN INDEXING\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def gather_filenames_and_metadata(bidsdata_raw):\n",
    "    \"\"\"\n",
    "    Build a dictionary describing files discovered in 'bidsdata_raw':\n",
    "      { folder_path: [ (file, datetime_object, run-#), ... ] }\n",
    "\n",
    "    1) We first check if the file can be assigned to a session (based on date).\n",
    "    2) We then assign runs to each date group inside that folder.\n",
    "    \"\"\"\n",
    "    file_metadata = {}\n",
    "\n",
    "    # Walk through the directory\n",
    "    for sub in os.listdir(bidsdata_raw):\n",
    "        for ses in os.listdir(os.path.join(bidsdata_raw, sub)):\n",
    "            for mode in os.listdir(os.path.join(bidsdata_raw, sub, ses)):\n",
    "                for file in os.listdir(os.path.join(bidsdata_raw, sub, ses, mode)):\n",
    "                    file_date_obj, date_format = return_date_given_filename(file)\n",
    "                    if not file_date_obj:\n",
    "                        print(f\"No date extracted for {file}\")\n",
    "                    else:\n",
    "                        # Build the path and deduce session number if needed\n",
    "                        file_date = datetime.strftime(file_date_obj, date_format)\n",
    "                        subject_id = sub.replace('sub-', '')\n",
    "                        file_session_num = extract_ses_given_date(subject_sessions, subject_id, file_date_obj)\n",
    "\n",
    "                        if file_session_num is not None:\n",
    "                            file_ses = f'ses-{file_session_num}'\n",
    "                            folder_path = os.path.join(bidsdata_raw, sub, file_ses, mode)\n",
    "\n",
    "                            if folder_path not in file_metadata:\n",
    "                                file_metadata[folder_path] = []\n",
    "                            file_info = (file, file_date_obj)\n",
    "                            if file_info not in file_metadata[folder_path]:\n",
    "                                file_metadata[folder_path].append(file_info)\n",
    "\n",
    "    # Assign runs within each folder path\n",
    "    for folder, files in file_metadata.items():\n",
    "        valid_files = [f for f in files if f[1] is not None]\n",
    "        invalid_files = [f for f in files if f[1] is None]\n",
    "        \n",
    "        # Group valid files by date\n",
    "        date_groups = defaultdict(list)\n",
    "        for filename, datetime_obj in valid_files:\n",
    "            date_only = datetime_obj.date()\n",
    "            date_groups[date_only].append((filename, datetime_obj))\n",
    "        \n",
    "        # Sort each date group by datetime, assign run indices\n",
    "        sorted_files = []\n",
    "        run_idx = 1\n",
    "        for date in sorted(date_groups.keys()):\n",
    "            date_group_files = sorted(date_groups[date], key=lambda x: x[1])\n",
    "            for filename, datetime_obj in date_group_files:\n",
    "                sorted_files.append((filename, datetime_obj, f'run-{run_idx}'))\n",
    "            run_idx += 1\n",
    "        \n",
    "        # Combine valid sorted files and invalid files\n",
    "        file_metadata[folder] = sorted_files + invalid_files\n",
    "\n",
    "    return file_metadata\n",
    "\n",
    "\n",
    "def return_run_given_file(file_metadata, filepath, filename):\n",
    "    \"\"\"\n",
    "    For a given file path (folder) and file name, return the assigned run\n",
    "    from file_metadata if it exists.\n",
    "    \"\"\"\n",
    "    if filepath in file_metadata:\n",
    "        file_list = file_metadata[filepath]\n",
    "        for file_entry in file_list:\n",
    "            if file_entry[0] == filename:\n",
    "                # file_entry = (filename, datetime_obj, run-#)\n",
    "                return file_entry[2]\n",
    "    return None\n",
    "\n",
    "\n",
    "def print_duplicates_filedict(file_dict):\n",
    "    \"\"\"\n",
    "    Debug function: print duplicates in the nested dictionary\n",
    "    containing file info. Looks for repeated (filename, run#).\n",
    "    \"\"\"\n",
    "    for folder, files in file_dict.items():\n",
    "        print(f\"Folder: {folder}\")\n",
    "        folder_list = []\n",
    "        for file_info in files:\n",
    "            if len(file_info) > 2:\n",
    "                # file_info = (filename, datetime_obj, run)\n",
    "                folder_list.append(f\"{file_info[0]}, {file_info[2]}\")\n",
    "            else:\n",
    "                print(f\"{file_info} - shorter than expected\")\n",
    "        \n",
    "        counts = Counter(folder_list)\n",
    "        duplicates = {item: count for item, count in counts.items() if count > 1}\n",
    "        \n",
    "        if duplicates:\n",
    "            print(\"Duplicates found:\")\n",
    "            for item, count in duplicates.items():\n",
    "                print(f\"{item}: {count} times\")\n",
    "        else:\n",
    "            print(\"No duplicates found.\")\n",
    "        print()\n",
    "\n",
    "\n",
    "def nested_dict_head(nested_dict, num_entries=5):\n",
    "    \"\"\"\n",
    "    Print a limited 'head' of a nested dictionary (for debugging).\n",
    "    \"\"\"\n",
    "    pp = pprint.PrettyPrinter(indent=2)\n",
    "    count = 0\n",
    "    for key, value in nested_dict.items():\n",
    "        print(f\"Key: {key}\")\n",
    "        if isinstance(value, dict):\n",
    "            for sub_key, sub_value in value.items():\n",
    "                print(f\"  Sub Key: {sub_key}\")\n",
    "                pp.pprint(sub_value)\n",
    "                count += 1\n",
    "                if count >= num_entries:\n",
    "                    return\n",
    "        else:\n",
    "            pp.pprint(value)\n",
    "            count += 1\n",
    "            if count >= num_entries:\n",
    "                return\n",
    "\n",
    "\n",
    "def count_keys(nested_dict):\n",
    "    \"\"\"\n",
    "    Count total keys in a nested dictionary.\n",
    "    \"\"\"\n",
    "    def recursive_count(d):\n",
    "        c = 0\n",
    "        if isinstance(d, dict):\n",
    "            c += len(d)\n",
    "            for k in d:\n",
    "                c += recursive_count(d[k])\n",
    "        return c\n",
    "    \n",
    "    total_keys = recursive_count(nested_dict)\n",
    "    print(f\"Total number of keys: {total_keys}\")\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# METADATA-EDITING FUNCTIONS (INTENDEDFOR, ECHOTIMES, ETC.)\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def index_bids_directory(directory):\n",
    "    \"\"\"\n",
    "    Recursively walk a BIDS directory, capturing relevant metadata for each JSON\n",
    "    and storing it in a dictionary. \n",
    "      layout[file_path] = { 'entities': <dict>, 'metadata': <dict> }\n",
    "    \"\"\"\n",
    "    layout = defaultdict(dict)\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            file_path = os.path.join(root, file)\n",
    "            entities = extract_bids_entities(file_path)\n",
    "            if file.endswith('.json'):\n",
    "                metadata = parse_json(file_path)\n",
    "                layout[file_path] = {'entities': entities, 'metadata': metadata}\n",
    "            else:\n",
    "                layout[file_path] = {'entities': entities}\n",
    "    return layout\n",
    "\n",
    "\n",
    "def update_intendedfor(layout, sub, ses, overwrite=False):\n",
    "    \"\"\"\n",
    "    Assign 'IntendedFor' field to field maps and other files in a BIDS dataset.\n",
    "\n",
    "    Steps:\n",
    "      1) Query all NIfTIs for that subject and session.\n",
    "      2) For fmaps (phasediff/magnitude), set 'IntendedFor' to refer to\n",
    "         associated _bold or _dwi scans.\n",
    "      3) For func or dwi, set 'IntendedFor' similarly in JSON if needed.\n",
    "      4) If 'TaskName' is missing for BOLD scans, add 'TaskName'.\n",
    "    \"\"\"\n",
    "    niftis = query_files(layout, sub=sub, ses=ses, suffix='.nii.gz')\n",
    "    for nifti_filepath in niftis:\n",
    "        if '.bidsignore' in nifti_filepath:\n",
    "            continue\n",
    "        nifti_filename = os.path.basename(nifti_filepath)\n",
    "        \n",
    "        # JSON sidecar\n",
    "        json_filepath = nifti_filepath.replace('.nii.gz', '.json')\n",
    "        json_filename = nifti_filename.replace('.nii.gz', '.json')\n",
    "\n",
    "        # Add TaskName if we find a BOLD but no 'TaskName' field\n",
    "        task = get_element('TaskName', layout, json_filepath)\n",
    "        if 'task' in nifti_filename and (task is None):\n",
    "            update_json_key(json_filepath, 'TaskName', 'Rest')\n",
    "            print(f'Added TaskName to {json_filename}')\n",
    "\n",
    "        # For fieldmap: add IntendedFor\n",
    "        if ('phase' in nifti_filename or 'magnitude' in nifti_filename):\n",
    "            if overwrite or get_element('IntendedFor', layout, json_filepath) is None:\n",
    "                intended_prev = get_element_raw('IntendedFor', nifti_filepath)\n",
    "                print(f\"For {nifti_filename} - previous: {intended_prev}\")\n",
    "                IntendedFor_list = intended_for_gen(nifti_filepath, niftis, layout)\n",
    "                print(f'Updated IntendedFor: {IntendedFor_list}')\n",
    "                update_json_key(json_filepath, 'IntendedFor', IntendedFor_list)\n",
    "\n",
    "        # For bold/dwi: add IntendedFor \n",
    "        if '_bold' in nifti_filename or '_dwi' in nifti_filename:\n",
    "            intended_prev = get_element_raw('IntendedFor', nifti_filepath)\n",
    "            print(f\"For {nifti_filename} - previous: {intended_prev}\")\n",
    "            IntendedFor_list = intended_for_gen(nifti_filepath, niftis, layout)\n",
    "            print(f'Updated IntendedFor: {IntendedFor_list}')\n",
    "            update_json_key(json_filepath, 'IntendedFor', IntendedFor_list)\n",
    "\n",
    "\n",
    "def intended_for_gen(matchto_json_path, niftis, layout):\n",
    "    \"\"\"\n",
    "    A simplified function that pairs up fieldmaps with BOLD/DWI (or vice versa)\n",
    "    within the same sub/ses. For each fieldmap, returns a list of BOLDs/DWIs,\n",
    "    or for each BOLD, returns the list of fieldmaps found in the directory.\n",
    "    \"\"\"\n",
    "    intended_for = []\n",
    "    for matching_nifti in niftis:\n",
    "        nifti_name = os.path.basename(matching_nifti)\n",
    "        # If matchto_json_path is a fieldmap, attach it to BOLDs or DWIs\n",
    "        if ('phase' in matchto_json_path or 'magnitude' in matchto_json_path):\n",
    "            if ('_bold' in matching_nifti or '_dwi' in matching_nifti):\n",
    "                path_piece = extract_IntendedFor_path(matching_nifti)\n",
    "                if path_piece:\n",
    "                    intended_for.append(path_piece)\n",
    "        # If matchto_json_path is a BOLD or DWI, attach it to fieldmaps\n",
    "        elif ('_bold' in matchto_json_path or '_dwi' in matchto_json_path):\n",
    "            if ('phase' in matching_nifti or 'magnitude' in matching_nifti):\n",
    "                path_piece = extract_IntendedFor_path(matching_nifti)\n",
    "                if path_piece:\n",
    "                    intended_for.append(path_piece)\n",
    "\n",
    "    return sorted(set(intended_for))\n",
    "\n",
    "\n",
    "# Helper: Query files in the layout that match sub, ses, and suffix\n",
    "def query_files(layout, sub=None, ses=None, suffix=None):\n",
    "    results = []\n",
    "    for file_path, info in layout.items():\n",
    "        if sub in file_path and ses in file_path:\n",
    "            if suffix and file_path.endswith(suffix):\n",
    "                results.append(file_path)\n",
    "    return results\n",
    "\n",
    "\n",
    "# Helper: Extract an element (e.g., 'TaskName') from the layout's metadata\n",
    "def get_element(element, layout, file_path):\n",
    "    if 'metadata' in layout[file_path]:\n",
    "        return layout[file_path]['metadata'].get(element, None)\n",
    "    return None\n",
    "\n",
    "\n",
    "# Helper: Extract an element directly from the JSON sidecar (bypassing the layout dict)\n",
    "def get_element_raw(element, nifti_file_path):\n",
    "    \"\"\"\n",
    "    Open the corresponding .json file (same path) and retrieve <element>.\n",
    "    \"\"\"\n",
    "    if '.nii.gz' in nifti_file_path:\n",
    "        json_file_path = nifti_file_path.replace('.nii.gz', '.json')\n",
    "    elif '.json' in nifti_file_path:\n",
    "        json_file_path = nifti_file_path\n",
    "    else:\n",
    "        return f\"Not a valid filepath: {nifti_file_path}\"\n",
    "    \n",
    "    if os.path.isfile(json_file_path):\n",
    "        with open(json_file_path, 'r') as file:\n",
    "            metadata = json.load(file)\n",
    "        return metadata.get(element, None)\n",
    "    else:\n",
    "        return f\"No JSON file associated with {nifti_file_path}\"\n",
    "\n",
    "\n",
    "# Helper: BIDS Entities from filepath (e.g., sub-04S0300, ses-1)\n",
    "def extract_bids_entities(file_path):\n",
    "    pattern = r\"sub-(?P<subject>[a-zA-Z0-9]+)(?:_ses-(?P<session>[a-zA-Z0-9]+))?\"\n",
    "    match = re.search(pattern, file_path)\n",
    "    if match:\n",
    "        return match.groupdict()\n",
    "    return {}\n",
    "\n",
    "\n",
    "# Helper: Parse JSON\n",
    "def parse_json(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        return json.load(f)\n",
    "\n",
    "\n",
    "# Helper: Add or update a JSON element\n",
    "def update_json_key(file_path, key, value):\n",
    "    with open(file_path, 'r', encoding='utf-8') as f:\n",
    "        data = json.load(f)\n",
    "    data[key] = value\n",
    "    with open(file_path, 'w', encoding='utf-8') as f:\n",
    "        json.dump(data, f, indent=4)\n",
    "    print(f'New field added/updated [{key}]: {value}')\n",
    "\n",
    "\n",
    "def extract_IntendedFor_path(full_path):\n",
    "    \"\"\"\n",
    "    Given a file path to something like:\n",
    "      /projects/.../sub-04S0300/ses-1/func/sub-04S0300_ses-1_task-rest_bold.nii.gz\n",
    "    Return the portion starting from 'sub-...' so that the JSON\n",
    "    can store `IntendedFor` with a relative path (BIDS standard).\n",
    "    \"\"\"\n",
    "    match = re.search(r'/sub-[^/]+/', full_path)\n",
    "    if match:\n",
    "        return full_path[match.end():]\n",
    "    return None\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# ECHO TIMES / PHASE ENCODING DIRECTIONS, JSON STUFF ETC.\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "def add_echotimes(layout, sub, ses):\n",
    "    \"\"\"\n",
    "    For all 'phasediff' files in a session, try to discover their \n",
    "    EchoTime1 and EchoTime2 from matching magnitude1/magnitude2 files.\n",
    "    \"\"\"\n",
    "    niftis = query_files(layout, sub=sub, ses=ses, suffix='.nii.gz')\n",
    "    for nifti_path in niftis:\n",
    "        if 'phasediff.' in nifti_path:\n",
    "            json_path = nifti_path.replace('.nii.gz', '.json')\n",
    "            EchoTime1 = get_element('EchoTime1', layout, json_path)\n",
    "            EchoTime2 = get_element('EchoTime2', layout, json_path)\n",
    "\n",
    "            # If missing EchoTime1 or EchoTime2, search matching mag1/mag2\n",
    "            if not isinstance(EchoTime1, (int, float)) or not isinstance(EchoTime2, (int, float)):\n",
    "                for nifti_path2 in niftis:\n",
    "                    # Magnitude1\n",
    "                    if 'magnitude1' in nifti_path2:\n",
    "                        json_path2 = nifti_path2.replace('.nii.gz', '.json')\n",
    "                        e_time = get_element('EchoTime', layout, json_path2)\n",
    "                        if e_time:\n",
    "                            update_json_key(json_path, 'EchoTime1', e_time)\n",
    "                            print(f\"Updated EchoTime1 in phasediff from {json_path2}\")\n",
    "\n",
    "                    # Magnitude2\n",
    "                    if 'magnitude2' in nifti_path2:\n",
    "                        json_path2 = nifti_path2.replace('.nii.gz', '.json')\n",
    "                        e_time = get_element('EchoTime', layout, json_path2)\n",
    "                        if e_time:\n",
    "                            update_json_key(json_path, 'EchoTime2', e_time)\n",
    "                            print(f\"Updated EchoTime2 in phasediff from {json_path2}\")\n",
    "\n",
    "                # Check if both times are present now, set EchoNumber\n",
    "                updated_EchoTime1 = get_element('EchoTime1', layout, json_path)\n",
    "                updated_EchoTime2 = get_element('EchoTime2', layout, json_path)\n",
    "                if updated_EchoTime1 and updated_EchoTime2:\n",
    "                    update_json_key(json_path, 'EchoNumber', 2)\n",
    "                elif updated_EchoTime1 or updated_EchoTime2:\n",
    "                    update_json_key(json_path, 'EchoNumber', 1)\n",
    "\n",
    "\n",
    "def add_direction(layout, sub, ses):\n",
    "    \"\"\"\n",
    "    If a file is named 'dir-PA' or 'dir-AP', ensure that the JSON \n",
    "    sidecar has PhaseEncodingDirection set to 'PA' or 'AP'.\n",
    "    \"\"\"\n",
    "    niftis = query_files(layout, sub=sub, ses=ses, suffix='.nii.gz')\n",
    "    for nifti_path in niftis:\n",
    "        if 'dir-PA' in nifti_path or 'dir-AP' in nifti_path:\n",
    "            json_path = nifti_path.replace('.nii.gz', '.json')\n",
    "            PhaseEncodingDirection = get_element('PhaseEncodingDirection', layout, json_path)\n",
    "            if not PhaseEncodingDirection:\n",
    "                if 'dir-PA' in nifti_path:\n",
    "                    update_json_key(json_path, 'PhaseEncodingDirection', 'j')\n",
    "                elif 'dir-AP' in nifti_path:\n",
    "                    update_json_key(json_path, 'PhaseEncodingDirection', 'j-')\n",
    "\n",
    "\n",
    "def scale_SliceTiming(numbers):\n",
    "    \"\"\"\n",
    "    Example helper: scale values to be between 0.01 and 0.1 if the SliceTiming \n",
    "    is drastically off. Not necessarily used in all pipelines.\n",
    "    \"\"\"\n",
    "    if not numbers:\n",
    "        raise ValueError(\"Input list cannot be empty.\")\n",
    "    \n",
    "    max_abs_value = max(abs(num) for num in numbers)\n",
    "    scale_factor = 1\n",
    "    while max_abs_value >= 1:\n",
    "        max_abs_value /= 10\n",
    "        scale_factor *= 10\n",
    "    while max_abs_value < 0.05:\n",
    "        max_abs_value *= 10\n",
    "        scale_factor /= 10\n",
    "\n",
    "    scaled_numbers = [num / scale_factor for num in numbers]\n",
    "    return scaled_numbers, scale_factor\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# ----------------------------------------------------------------------\n",
    "# BIDS filenaming, for files which don't have a BidsGuess field in JSON\n",
    "# ----------------------------------------------------------------------\n",
    "\n",
    "\n",
    "# Move and rename those files with no \"BidsGuess\" in JSON\n",
    "def filename_no_bidsguess(filepath, filename, sub, ses):\n",
    "    path = os.path.normpath(filepath)\n",
    "    filename = os.path.basename(path)\n",
    "    task, acq, direction, run, end = \"\",\"\",\"\",\"\",\"\"\n",
    "    \n",
    "    ##### extension                                \n",
    "    if filename.endswith('.nii.gz'):\n",
    "        file_ext = 'nii.gz'\n",
    "    else:\n",
    "        file_ext = filename.split('.')[-1]\n",
    "\n",
    "    dir_name = os.path.basename(os.path.dirname(path))\n",
    "    \n",
    "    ##### MODE\n",
    "    protocol = str(get_element_raw(\"SeriesDescription\", path))\n",
    "    mode_of_folder = find_mode(dir_name)\n",
    "    if protocol:\n",
    "        mode = find_mode(protocol)\n",
    "        if mode == \"UnrecognizedFileType\":\n",
    "            mode = mode_of_folder\n",
    "            if mode_of_folder == \"UnrecognizedFileType\":\n",
    "                mode_of_file = find_mode(filename)\n",
    "                mode = mode_of_file\n",
    "                if mode_of_file == \"UnrecognizedFileType\":\n",
    "                    return f'Unable to extract mode for: {path}'\n",
    "    else:\n",
    "        mode = mode_of_folder\n",
    "        if mode_of_folder == \"UnrecognizedFileType\":\n",
    "            mode_of_file = find_mode(filename)\n",
    "            mode = mode_of_file\n",
    "            if mode_of_file == \"UnrecognizedFileType\":\n",
    "                return f'Unable to extract mode for: {path}'\n",
    "    if \"UnrecognizedFileType\" not in mode:\n",
    "        \n",
    "        \n",
    "        ###### DIR-\n",
    "        direction_extracted = str(get_element_raw(\"PhaseEncodingDirection\", path))\n",
    "        axis_extracted = str(get_element_raw(\"PhaseEncodingAxis\", path))\n",
    "        if direction_extracted:\n",
    "            if 'j-' in direction_extracted: #'j-': 'Anterior-Posterior'\n",
    "                direction = 'dir-AP'\n",
    "            elif 'j' in direction_extracted: #'j': Posterior-Anterior'\n",
    "                direction = 'dir-PA'\n",
    "        elif axis_extracted:\n",
    "            if 'j-' in axis_extracted: #'j-': 'Anterior-Posterior'\n",
    "                    direction = 'dir-AP'\n",
    "            elif 'j' in axis_extracted: #'j': Posterior-Anterior'\n",
    "                direction = 'dir-PA'\n",
    "        else:\n",
    "            if 'dwi' in mode or 'func' in mode:\n",
    "                return f\"Unable to extract dir (direction: {direction_extracted}) for {path}; mode is {mode}\"\n",
    "            else:\n",
    "                direction = None\n",
    "\n",
    "\n",
    "        ####### RUN-\n",
    "        run_num = str(get_element_raw(\"SeriesNumber\", path))\n",
    "        if run_num:\n",
    "            run = 'run-' + run_num\n",
    "        else:\n",
    "            if not 'fmap' in mode:\n",
    "                return f\"Unable to extract run for {path}; mode is {mode}\"\n",
    "            else:\n",
    "                run = None\n",
    "\n",
    "        ####### ACQ-, END & TASK-\n",
    "        if mode == 'anat':\n",
    "            protocol = str(get_element_raw(\"SeriesDescription\", path))\n",
    "            protocol_lower = protocol.lower()\n",
    "            if 't1' in protocol_lower:\n",
    "                end='T1w'\n",
    "            elif 't2' in protocol_lower:\n",
    "                end='T2w'\n",
    "            \n",
    "            if 'SPC' in protocol:\n",
    "                acq = 'acq-spc3'\n",
    "            elif 'MPR' in protocol:\n",
    "                acq = 'acq-tfl3'\n",
    "            elif 'flash' in protocol:\n",
    "                if '3.5mm' in protocol:\n",
    "                    acq='acq-flash3'\n",
    "                if '2mm' in protocol:\n",
    "                    acq='acq-flash2'\n",
    "                else:\n",
    "                    acq='acq-flash'\n",
    "            else:\n",
    "                return f\"Unable to extract acq for {path}; mode is {mode}\"\n",
    "\n",
    "        if mode == 'func':\n",
    "            task = 'task-rest'\n",
    "            end = 'bold'\n",
    "\n",
    "            protocol = str(get_element_raw(\"SeriesDescription\", path))\n",
    "            if 'MB_bold' in protocol:\n",
    "                acq = 'acq-epfid2m5'\n",
    "            elif 'ep2d_bold' in protocol:\n",
    "                acq = 'acq-epfid2'\n",
    "            else:\n",
    "                return f\"Unable to extract acq for {path}; mode is {mode}\"\n",
    "\n",
    "        if mode == 'fmap':\n",
    "            e = str(get_element_raw(\"EchoNumber\", path))\n",
    "            image = get_element_raw(\"ImageType\", path)\n",
    "            if image:\n",
    "                if len(image) > 2:\n",
    "                    if image[2] == \"OTHER\":\n",
    "                        if len(image) > 3:\n",
    "                            if image[3] == \"REAL\":\n",
    "                                acq = 'acq-real' + e\n",
    "                                end = 'magnitude' + e\n",
    "                            elif image[3] == \"IMAGINARY\":\n",
    "                                acq = 'acq-imaginary' + e\n",
    "                                end = 'magnitude' + e\n",
    "                            elif image[3] == \"PHASE\":\n",
    "                                end = 'phase' + e\n",
    "                        else:\n",
    "                            end = 'magnitude' + e\n",
    "\n",
    "                    elif \"M\" in image[2] or \"P\" in image[2]:\n",
    "                        acq = 'acq-fm2'\n",
    "                        if image[2] == \"M\":\n",
    "                            end = 'magnitude' + e\n",
    "                        elif image[2] == \"P\":\n",
    "                            end = 'phasediff'\n",
    "                else:\n",
    "                    return f\"Unable to extract acq for {path}, ImageType is {image}\"\n",
    "            else:\n",
    "                return f\"Unable to extract acq for {path}, no ImageType\"\n",
    "\n",
    "\n",
    "        if mode == 'dwi':\n",
    "            end = 'dwi'\n",
    "            sequence = str(get_element_raw(\"SequenceName\", path))\n",
    "            scanseq = str(get_element_raw(\"ScanningSequence\", path))\n",
    "            if sequence:\n",
    "                if \"ep_b0\" in sequence:\n",
    "                    acq = 'acq-epb0'\n",
    "            elif scanseq:\n",
    "                if \"EP\\\\RM\" in scanseq:\n",
    "                    acq = 'acq-eprm'\n",
    "                    \n",
    "            else:\n",
    "                return f\"Unable to extract acq for {path}\"\n",
    "            \n",
    "                \n",
    "\n",
    "\n",
    "        parts = [sub, ses, task, acq, direction, run, end]\n",
    "        parts = [part for part in parts if part]  # Remove empty parts\n",
    "        new_filename = '_'.join(parts)\n",
    "        new_filename = new_filename.replace('__','_')\n",
    "\n",
    "        # Add extension\n",
    "        #print(f\"Extension is: {file_ext}\")\n",
    "        name_final = new_filename + '.' + file_ext\n",
    "        name_final = name_final.replace('..','.')\n",
    "        \n",
    "        return name_final\n",
    "    \n",
    "    else:\n",
    "        return f\"Unable to extract mode for {path}\"\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Make subject_sessions list\n",
    "subject_sessions = create_subject_sessions_dict2(source_images)\n",
    "\n",
    "# Extract sublists\n",
    "ids = extract_subject_ids(subject_sessions)\n",
    "#session_ids = extract_session_ids(subject_sessions)\n",
    "#session_nums = extract_session_nums(subject_sessions)\n",
    "\n",
    "\n",
    "# Make filenames metadata list\n",
    "bids_raw = '/projects/f_ah1491_1/open_data/NAPLS3/bidsdata_raw'\n",
    "#file_metadata = gather_filenames_and_metadata(bids_raw)\n",
    "\n",
    "# Example, subject sessions\n",
    "\n",
    "session_num = extract_ses_given_date(subject_sessions, '01S0301', '2015-03-17')\n",
    "print(f'Session for sub 01S0301, date 20150317, is: {session_num}')\n",
    "\n",
    "print(count_keys(subject_sessions))\n",
    "\n",
    "print(\"\\nSubject sessions, 06S0333: \\n\")\n",
    "print(subject_sessions['06S0333'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Step 1: Unzip and Convert DICOMS\n",
    "source_images = \"/projects/f_ah1491_1/open_data/NAPLS3/sourcedata/image03\"\n",
    "dicom_directory =\"/scratch/f_ah1491_1/open_data/NAPLS3/sourcedata/image03\" #This should be somewhere that can hold a lot of files, like a scratch folder\n",
    "unzip_and_convert_dicom(source_images, dicom_directory)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Move unzipped source files to bidsdata ##################\n",
    "source_folder = source_images\n",
    "target_dir = '/projects/f_ah1491_1/open_data/NAPLS3/bidsdata'\n",
    "if not os.path.exists(target_dir):\n",
    "    os.makedirs(target_dir, exist_ok=True)\n",
    "\n",
    "exists_already = []\n",
    "no_session_number = []\n",
    "failed_to_extract = []\n",
    "no_bids_guess = []\n",
    "bids_guess_invalid = []\n",
    "not_valid_source_file = []\n",
    "no_return_filename_no_bidsguess = []\n",
    "no_json_file = []\n",
    "moved = []\n",
    "count_moved = 0\n",
    "\n",
    "for session_folder in os.listdir(source_folder):\n",
    "    if os.path.isdir(os.path.join(source_folder, session_folder)) and session_folder.startswith('0'):\n",
    "        # Return subject_id from file\n",
    "        subject_id = return_subject_id_given_session_id(session_folder)\n",
    "        sub = 'sub-' + subject_id\n",
    "        for mode_folder1 in os.listdir(os.path.join(source_folder, session_folder)):\n",
    "            if os.path.isdir(os.path.join(source_folder, session_folder, mode_folder1)):\n",
    "                for file in os.listdir(os.path.join(source_folder, session_folder, mode_folder1)):\n",
    "                    src_path = False\n",
    "                    if not os.path.isdir(os.path.join(source_folder, session_folder, mode_folder1, file)):\n",
    "                        filename = file\n",
    "                        mode_folder = mode_folder1\n",
    "                        src_path = os.path.join(source_folder, session_folder, mode_folder, file)\n",
    "                    elif file == subject_id:\n",
    "                        for mode_folder2 in os.listdir(os.path.join(source_folder, session_folder, mode_folder1, file)):\n",
    "                            if os.path.isdir(os.path.join(source_folder, session_folder, mode_folder1, file, mode_folder2)):\n",
    "                                for file2 in os.listdir(os.path.join(source_folder, session_folder, mode_folder1, file, mode_folder2)):\n",
    "                                    if os.path.isfile(os.path.join(source_folder, session_folder, mode_folder1, file, mode_folder2, file2)):\n",
    "                                        src_path = os.path.join(source_folder, session_folder, mode_folder1, file, mode_folder2, file2)\n",
    "                                        mode_folder = mode_folder2\n",
    "                                        filename = file2\n",
    "                                    \n",
    "                    else:\n",
    "                        continue\n",
    "                                                  \n",
    "                    if src_path:\n",
    "                        # Return ses number from file\n",
    "                        file_date_obj = return_date_given_filename(filename)\n",
    "                        \n",
    "                        \n",
    "                        # Handle file_date_obj errors\n",
    "                        if not file_date_obj:\n",
    "                            print(f\"No file_date extracted from {filename}\\n\")\n",
    "                            no_session_number.append(file)\n",
    "                        \n",
    "                        else: # If file_date_obj successfully extracted, find session number\n",
    "                            file_session_number = extract_ses_given_date(subject_sessions, subject_id, file_date_obj)\n",
    "\n",
    "                            # Handle session number errors\n",
    "                            if \"Error\" in file_session_number:\n",
    "                                if \"no sessions found within\" in file_session_number: \n",
    "                                    print(f\"File date could not be found for sub-{subject_id}, {file_date_obj}, {filename}\")\n",
    "                                    print(f\"All dates for {subject_id}:\\n {extract_dates_given_sub(subject_sessions, subject_id)}\\n\\n\")\n",
    "                                    no_session_number.append(filename)\n",
    "                                else:\n",
    "                                    print(f\"No session number extracted from {filename}: {file_session_number}\\n\")\n",
    "                                    failed_to_extract.append(filename)\n",
    "                            \n",
    "                            else: # If the file_session_number successfully extracted\n",
    "                                \n",
    "                                # Initialize correct session\n",
    "                                \n",
    "                                ses = f'ses-{str(file_session_number)}'\n",
    "\n",
    "                                ## Create the new filename for renaming\n",
    "                                new_filename = filename.lower()\n",
    "\n",
    "                                # Keep the extension                                \n",
    "                                if filename.endswith('.nii.gz'):\n",
    "                                    file_ext = 'nii.gz'\n",
    "                                else:\n",
    "                                    file_ext = filename.split('.')[-1]\n",
    "                                    \n",
    "                                # Extract mode\n",
    "                                series = get_element_raw(\"SeriesDescription\", src_path)\n",
    "                                mode = find_mode(series)\n",
    "                                \n",
    "                                # Make target folder\n",
    "                                target_folder = os.path.join(target_dir, sub, ses, mode)\n",
    "\n",
    "                                # Extract filename via BidsGuess\n",
    "                                bids_guess = get_element_raw(\"BidsGuess\", src_path)\n",
    "                                print(bids_guess)\n",
    "                                \n",
    "                                # NO BidsGuess:\n",
    "                                if 'BidsGuess not found in the metadata' in bids_guess:\n",
    "                                    name_final = filename_no_bidsguess(src_path, filename, sub, ses)\n",
    "                                    print(f'function filename_no_bidsguess-> {name_final}')\n",
    "                                    \n",
    "                                    if not 'Unable' in name_final or 'unable' in name_final:\n",
    "                                        if not os.path.exists(target_folder):\n",
    "                                            os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "                                        target_path = os.path.join(target_dir, sub, ses, mode, name_final)\n",
    "                            \n",
    "                                        # Handle case where the new path already exists\n",
    "                                        if not os.path.exists(target_path):\n",
    "                                            # Perform the renaming, setting target_path even if there is no duplicate\n",
    "                                            target_path = os.path.join(target_folder, name_final)\n",
    "                                            shutil.copy2(src_path, target_path)\n",
    "                                            print(f\"MOVED {name_final} from {file}\")\n",
    "                                            moved.append(target_path)\n",
    "                                        else:\n",
    "                                            exists_already.append(f'{src_path} -> {name_final}')\n",
    "                                            #print(f'\\nPath exists already: {target_path}; cannot move {file}\\n\\n')\n",
    "                                    \n",
    "                                    else: \n",
    "                                        no_return_filename_no_bidsguess.append(name_final)\n",
    "                                        print('appended to no_return_filename_no_bidsguess')\n",
    "                                                  \n",
    "    \n",
    "                                elif 'Not a valid filepath' in bids_guess:\n",
    "                                    not_valid_source_file.append(src_path)\n",
    "                                    print('appended to not_valid_source_file')\n",
    "                                elif 'No JSON file associated' in bids_guess:\n",
    "                                    no_json_file.append(src_path)\n",
    "                                    print('appended to no_json_file')\n",
    "                                \n",
    "                                                  \n",
    "                                # VALID BidsGuess: \n",
    "                                elif len(bids_guess) > 1:\n",
    "                                    if 'acq' in bids_guess[1] or 'run' in bids_guess[1]:\n",
    "                                    \n",
    "                                        # Extract mode\n",
    "                                        mode = bids_guess[0]\n",
    "                                        if mode == 'UnrecognizedFileType':\n",
    "                                            mode = find_mode(mode_folder)\n",
    "\n",
    "                                        # Make target folder\n",
    "                                        target_folder = os.path.join(target_dir, sub, ses, mode)\n",
    "                                        if not os.path.exists(target_folder):\n",
    "                                            os.makedirs(target_folder, exist_ok=True)\n",
    "\n",
    "                                        # Create filename\n",
    "                                        if sub in bids_guess[1] and ses in bids_guess[1]:\n",
    "                                            if 'func' in mode:\n",
    "                                                new_filename = bids_guess.replace(ses, f'{ses}_task-rest')\n",
    "                                            else:\n",
    "                                                new_filename = bids_guess\n",
    "\n",
    "                                        elif sub in bids_guess[1] and ses not in bids_guess[1]:\n",
    "                                            if 'func' in mode:\n",
    "                                                new_filename = bids_guess[1].replace(sub, f'{sub}_{ses}_task-rest')\n",
    "                                            else:\n",
    "                                                new_filename = bids_guess[1].replace(sub, f'{sub}_{ses}')\n",
    "\n",
    "                                        elif ses in bids_guess[1] and sub not in bids_guess[-1]:\n",
    "                                            if 'func' in mode:\n",
    "                                                end_filename = bids_guess[1].replace(ses, f'{ses}_task-rest')\n",
    "                                                new_filename = '_'.join([sub, end_filename])\n",
    "                                            else:\n",
    "                                                new_filename = '_'.join([sub, bids_guess[-1]])\n",
    "\n",
    "                                        else:\n",
    "                                            if 'func' in mode:\n",
    "                                                new_filename = '_'.join([sub, ses, 'task-rest', bids_guess[-1]])\n",
    "                                            else:\n",
    "                                                new_filename = '_'.join([sub, ses, bids_guess[-1]])\n",
    "\n",
    "\n",
    "                                        # Clean and Add extension\n",
    "                                        new_filename = new_filename.replace('__','_')\n",
    "                                        name_final = new_filename + '.' + file_ext\n",
    "                                        print('name_final is:', name_final)\n",
    "                                        target_path = os.path.join(target_dir, sub, ses, mode, name_final)\n",
    "\n",
    "                                        # Handle case where the new path already exists\n",
    "                                        if not os.path.exists(target_path):\n",
    "                                            # Perform the renaming, setting target_path even if there is no duplicate\n",
    "                                            target_path = os.path.join(target_folder, name_final)\n",
    "                                            shutil.copy2(src_path, target_path)\n",
    "                                            print(f\"MOVED {name_final} from {file}\")\n",
    "                                            moved.append(target_path)\n",
    "                                            count_moved +=1\n",
    "                                        else:\n",
    "                                            exists_already.append(f'{src_path} -> {name_final}')\n",
    "                                            count_moved +=1\n",
    "                                            #print(f'\\nPath exists already: {target_path}; cannot move {file}\\n\\n')\n",
    "\n",
    "                  \n",
    "                                \n",
    "                                else:\n",
    "                                    bids_guess_invalid.append(f'BidsGuess: {bids_guess}, file: {src_path}')\n",
    "                                                  \n",
    "                            \n",
    "                                        \n",
    "                                        \n",
    "#print(f'Exists already, couldnt move: {len(exists_already)} files')\n",
    "print(f'\\n\\n\\nNo session number found for the date of {len(no_session_number)} files')\n",
    "print(f'The function to extract_session_number didnt work for {len(failed_to_extract)} files')\n",
    "print(f'There was no BidsGuess in the .json file for {len(no_bids_guess)} files')\n",
    "print(f'BidsGuess didnt have valid format for {len(bids_guess_invalid)} files')\n",
    "print(f'Couldnt convert source to .json to find BidsGuess for {len(not_valid_source_file)} files')\n",
    "print(f'Couldnt find JSON file for {len(no_json_file)} files')\n",
    "print(f'Couldnt move, exists already-- {len(exists_already)} files')\n",
    "print(f'Function filename_no_bidsguess didnt return anything for {len(no_return_filename_no_bidsguess)} files')\n",
    "\n",
    "#print(f'Moved: {count_moved} files')\n",
    "\n",
    "src_path_not_moved = []\n",
    "src_name_not_moved = []\n",
    "name_final_already_exists = []\n",
    "\n",
    "for string in exists_already: # len 2801 files\n",
    "    # Find the index of the first occurrence of '->'\n",
    "    parts = string.split(' -> ')\n",
    "    \n",
    "    # Check if ' -> ' is present and return the second part\n",
    "    if len(parts) > 1:\n",
    "        src_path = parts[0]\n",
    "        src_path_not_moved.append(src_path)\n",
    "        path = os.path.normpath(src_path)\n",
    "        filename = os.path.basename(path)\n",
    "        src_name_not_moved.append(filename)\n",
    "        \n",
    "        name_final = parts[1]\n",
    "        name_final_already_exists.append(name_final)   \n",
    "\n",
    "print('Unique source name not moved', len(set(src_name_not_moved)))\n",
    "print('Unique  name_final which already_exists', len(set(name_final_already_exists)))\n",
    "\n",
    "# See how many unique files are in no_bids_guess_filenames; len total 1969 files\n",
    "print(len(set(no_return_filename_no_bidsguess))) # unique: 1915\n",
    "#print(no_return_filename_no_bidsguess) \n",
    "\n",
    "# See how many have no json file\n",
    "print(len(set(no_json_file))) #len = 30 files\n",
    "#print(no_json_file)\n",
    "          "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "####### COUNTING BEFORE & AFTER ###########\n",
    "source_files = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(source_images):\n",
    "    for filename in filenames:  # Loop over each file\n",
    "        if filename.endswith('.nii.gz') or filename.endswith('.json') or filename.endswith('.bval') or filename.endswith('.bvec'):\n",
    "            source_files.append(filename)\n",
    "\n",
    "bids_files = []\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk(bids_directory):\n",
    "    for filename in filenames:  # Loop over each file\n",
    "        if filename.endswith('.nii.gz') or filename.endswith('.json') or filename.endswith('.bval') or filename.endswith('.bvec'):\n",
    "            bids_files.append(filename)\n",
    "\n",
    "print('Count of source dir files:', len(source_files), 'bidsdata_all files:', len(bids_files)) \n",
    "#Count of source dir files: 127757 bidsdata_all files: 41155\n",
    "print('Unique source dir files:', len(set(source_files)), 'Unique bidsdata_all files:', len(set(bids_files)))\n",
    "#Unique source dir files: 83910 Unique bidsdata_all files: 41155"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### ADD INTENDEDFOR TO THE JSON ##########\n",
    "directory = '/projects/f_ah1491_1/open_data/NAPLS3/fmap_test'\n",
    "\n",
    "layout = index_bids_directory(directory)\n",
    "for sub in os.listdir(bids_directory):\n",
    "    if os.path.isdir(os.path.join(bids_directory,sub)):\n",
    "        for ses in os.listdir(os.path.join(bids_directory,sub)):\n",
    "            if os.path.isdir(os.path.join(bids_directory,sub,ses)):\n",
    "                update_intendedfor(layout, sub, ses, overwrite=True)\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "######### Generate dataset_description.json #########\n",
    "dataset_description = {\n",
    "    \"Name\": \"1/9 to 9/9 Predictors and Mechanisms of Conversion to Psychosis (NAPLS3)\",\n",
    "    \"BIDSVersion\": \"1.4.0\",\n",
    "    \"License\": \"License info here\",\n",
    "    \"Authors\": [\"Jean Addington\", \"Kristin Cadenhead\", \"Tyrone Cannon\", \"Barbara Cornblatt\", \"Daniel Mathalon\", \"Diana Perkins\", \"Larry Seidman\", \"Elaine Walker\", \"Scott Woods\"],\n",
    "}\n",
    "bidsdata = '/projects/f_ah1491_1/open_data/NAPLS3'\n",
    "with open(os.path.join(bidsdata, \"dataset_description.json\"), \"w\") as json_file:\n",
    "    json.dump(dataset_description, json_file, indent=4)\n",
    "\n",
    "print(f\"Dataset description created at {bidsdata}.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DEBUGGING & UTILITY CELLS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Print/Check NIfTI header (dimensions, volumes, etc.)\n",
    "import os\n",
    "import nibabel as nib\n",
    "\n",
    "for dirpath, dirnames, filenames in os.walk('/home/kj537/_f_ah1491_1/open_data/NAPLS3/synmap_test/sub-09S0348/'):\n",
    "    for file in filenames:\n",
    "        print('yes')\n",
    "        if file.endswith('.nii.gz'):\n",
    "            filepath = os.path.join(dirpath, file)\n",
    "            img = nib.load(filepath)  # Use 'filepath' instead of 'file'\n",
    "\n",
    "            # Extract the header\n",
    "            header = img.header\n",
    "\n",
    "            dim = header['dim']  # Access 'dim' field directly\n",
    "            print(f\"{file}: \\n Header = \\n{header}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### RENAMING files ###############\n",
    "\n",
    "#subjIDs_list = ids\n",
    "#subjIDs_list= ['sub-04S0318','sub-04S0350','sub-05S0326','sub-06S0309','sub-06S0341','sub-07S0341','sub-07S0399']\n",
    "bids_directory = \"/projects/f_ah1491_1/open_data/NAPLS3/bidsdata\"\n",
    "\n",
    "for root, _, files in os.walk(target_dir):\n",
    "    for file in files:\n",
    "        src_path = os.path.join(root, file)\n",
    "                        \n",
    "        if 'acq-_' in file:\n",
    "            new_filename = file.replace('acq-_','')\n",
    "            target_path = os.path.join(root, new_filename)\n",
    "            try:\n",
    "                os.rename(src_path, target_path)\n",
    "                print(f'Renamed to {new_filename} from {file}')\n",
    "            except Exception as e:\n",
    "                print(f\"Could not rename {file}, error: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Moving groups of files to .bidsignore ################\n",
    "\n",
    "#subjIDs_list = ids\n",
    "subjIDs_list= [] # 'sub-09S0348' 'sub-04S0300'\n",
    "target_dir = \"/projects/f_ah1491_1/open_data/NAPLS3/synmap_test\"\n",
    "\n",
    "for sub in os.listdir(target_dir):\n",
    "    #print(f\"\\n\\n\\n SUBJECT: {subject}\")\n",
    "    if os.path.isdir(os.path.join(target_dir, sub)):\n",
    "        for ses in os.listdir(os.path.join(target_dir, sub)):\n",
    "            if os.path.isdir(os.path.join(target_dir, sub, ses)):\n",
    "                #print(f\"SES: {ses}\")\n",
    "                for mode in os.listdir(os.path.join(target_dir, sub, ses)):\n",
    "                    src_path = False\n",
    "                    target_folder = False\n",
    "                    if 'fmap' in mode:\n",
    "                    if os.path.isdir(os.path.join(target_dir, sub, ses, mode)):\n",
    "                        #print(f\"MODE: {mode}\")\n",
    "                        if 'discard' in mode:\n",
    "                            try:\n",
    "                                os.system(f'rm -r {os.path.join(target_dir, sub, ses, mode)}')\n",
    "                            except Exception as e:\n",
    "                                print(f\"Could not delete 'discard': {e}\")\n",
    "\n",
    "\n",
    "                        \n",
    "                        for file in os.listdir(os.path.join(target_dir, sub, ses, mode)):\n",
    "                            ## What files go in .bidsignore\n",
    "                            \n",
    "                                src_path = (os.path.join(target_dir, sub, ses, mode, file))\n",
    "                                target_folder = (os.path.join(target_dir, '.bidsignore', sub, ses, mode))\n",
    "                                #print(file)\n",
    "                            \n",
    "                                if not os.path.exists(target_folder):\n",
    "                                    os.makedirs(target_folder, exist_ok=True)\n",
    "                                target_path = os.path.join(target_folder, file)\n",
    "                                try:\n",
    "                                    shutil.move(src_path, target_path)\n",
    "                                    print(\"Moved to:\",target_path)\n",
    "                                except Exception as e:\n",
    "                                    print(f\"Could not rename {file}, error: {e}\")\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############## Move a single file to .bidsignore #############\n",
    "src_path = '/projects/f_ah1491_1/open_data/NAPLS3/synmap_test/sub-09S0348/ses-3/dwi/sub-09S0348_ses-3_acq-epb2_dir-AP_run-9_dwi.nii.gz'\n",
    "file = 'sub-09S0348_ses-3_acq-epb2_dir-AP_run-9_dwi.nii.gz'\n",
    "target_folder = '/projects/f_ah1491_1/open_data/NAPLS3/synmap_test/.bidsignore/sub-09S0348/ses-3/dwi/'\n",
    "if not os.path.exists(target_folder):\n",
    "    os.makedirs(target_folder, exist_ok=True)\n",
    "target_path = os.path.join(target_folder, file)\n",
    "try:\n",
    "    shutil.move(src_path, target_path)\n",
    "    print(\"Moved to:\",target_path)\n",
    "except Exception as e:\n",
    "    print(f\"Could not rename {file}, error: {e}\")\n",
    "\n",
    "                        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Check filenames: To check all .nii.jz have a corresponding .json #########\n",
    "no_json=[]\n",
    "#print(\"To check all .nii.jz have a corresponding .json:\")\n",
    "bids_directory = '/projects/f_ah1491_1/open_data/NAPLS3/bidsdata'\n",
    "for subject in os.listdir(bids_directory):\n",
    "    if os.path.isdir(os.path.join(bids_directory, subject)):\n",
    "        if not 'bidsignore' in subject:\n",
    "            for ses in os.listdir(os.path.join(bids_directory, subject)):\n",
    "                if os.path.isdir(os.path.join(bids_directory, subject, ses)):\n",
    "                    #print(f\"SES: {ses}\")\n",
    "                    for mode in os.listdir(os.path.join(bids_directory, subject, ses)):\n",
    "                        mode_fp = os.path.join(bids_directory, subject, ses, mode)\n",
    "                        if os.path.isdir(mode_fp):\n",
    "                            for file in os.listdir(mode_fp):\n",
    "                                filename=file.split('.')\n",
    "                                if filename[-1] == 'gz':\n",
    "                                    file_base = file.replace('.nii.gz', '')\n",
    "                                    if not os.path.exists(os.path.join(mode_fp, f'{file_base}.json')):\n",
    "                                        print(f\"No .json for {os.path.join(mode_fp,file)}\")\n",
    "                                        no_json.append(file)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "########### Check filenames: To check all filetypes are in the appropriate mode folder ############\n",
    " \n",
    "\n",
    "import shutil\n",
    "\n",
    "bids_directory = \"/projects/f_ah1491_1/open_data/NAPLS3/bidsdata\"\n",
    "#print(\"To check all filetypes are in the appropriate mode folder:\")\n",
    "for subject in os.listdir(bids_directory):\n",
    "    if os.path.isdir(os.path.join(bids_directory, subject)) and '.' not in subject:\n",
    "            for ses in os.listdir(os.path.join(bids_directory, subject)):\n",
    "                if os.path.isdir(os.path.join(bids_directory, subject, ses)):\n",
    "                    #print(f\"SES: {ses}\")\n",
    "                    for mode in os.listdir(os.path.join(bids_directory, subject, ses)):\n",
    "                        mode_fp = os.path.join(bids_directory, subject, ses, mode)\n",
    "                        if os.path.isdir(mode_fp):\n",
    "                            for file in os.listdir(mode_fp):\n",
    "                                current_filepath = os.path.join(mode_fp, file)\n",
    "                                # Separate the filename into the '_' separated parts\n",
    "                                filename_parts=file.split('_')\n",
    "                                \n",
    "                                file_end = filename_parts[-1].split('.')\n",
    "                                \n",
    "                                # Check what ending the file has & compare to what mode it has\n",
    "                                if file == '.ipynb_checkpoints':\n",
    "                                    continue\n",
    "                                if file_end[0] == 'bold':\n",
    "                                    mode_should_be='func'\n",
    "                                    if not mode == mode_should_be:\n",
    "                                        destination_path = os.path.join(bids_directory, subject, ses, mode_should_be, file)\n",
    "                                        try:\n",
    "                                            #shutil.move(current_filepath, destination_path)\n",
    "                                            print(f\"File moved from {current_filepath} to {destination_path} successfully.\")\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"An error occurred file from {current_filepath} to {destination_path}: {e}\")\n",
    "                                elif file_end[0] == 'T1w':\n",
    "                                    mode_should_be='anat'\n",
    "                                    if not mode == mode_should_be:\n",
    "                                        destination_path = os.path.join(bids_directory, subject, ses, mode_should_be, file)\n",
    "                                        try:\n",
    "                                            #shutil.move(current_filepath, destination_path)\n",
    "                                            print(f\"File moved from {current_filepath} to {destination_path} successfully.\")\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"An error occurred file from {current_filepath} to {destination_path}: {e}\")\n",
    "                                elif file_end[0] == 'T2w':\n",
    "                                    mode_should_be='anat'\n",
    "                                    if not mode == mode_should_be:\n",
    "                                        destination_path = os.path.join(bids_directory, subject, ses, mode_should_be, file)\n",
    "                                        try:\n",
    "                                            #shutil.move(current_filepath, destination_path)\n",
    "                                            print(f\"File moved from {current_filepath} to {destination_path} successfully.\")\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"An error occurred file from {current_filepath} to {destination_path}: {e}\")\n",
    "                                elif file_end[0] == 'FLASH':\n",
    "                                    mode_should_be='anat'\n",
    "                                    if not mode == mode_should_be:\n",
    "                                        destination_path = os.path.join(bids_directory, subject, ses, mode_should_be, file)\n",
    "                                        try:\n",
    "                                            #shutil.move(current_filepath, destination_path)\n",
    "                                            print(f\"File moved from {current_filepath} to {destination_path} successfully.\")\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"An error occurred file from {current_filepath} to {destination_path}: {e}\")\n",
    "                                elif file_end[0] == 'dwi':\n",
    "                                    mode_should_be='dwi'\n",
    "                                    if not mode == mode_should_be:\n",
    "                                        destination_path = os.path.join(bids_directory, subject, ses, mode_should_be, file)\n",
    "                                        try:\n",
    "                                            #shutil.move(current_filepath, destination_path)\n",
    "                                            print(f\"File moved from {current_filepath} to {destination_path} successfully.\")\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"An error occurred file from {current_filepath} to {destination_path}: {e}\")\n",
    "                                elif file_end[0] == 'magnitude1':\n",
    "                                    mode_should_be='fmap'\n",
    "                                    if not mode == mode_should_be:\n",
    "                                        destination_path = os.path.join(bids_directory, subject, ses, mode_should_be, file)\n",
    "                                        try:\n",
    "                                            #shutil.move(current_filepath, destination_path)\n",
    "                                            print(f\"File moved from {current_filepath} to {destination_path} successfully.\")\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"An error occurred file from {current_filepath} to {destination_path}: {e}\")\n",
    "                                elif file_end[0] == 'magnitude2':\n",
    "                                    mode_should_be='fmap'\n",
    "                                    if not mode == mode_should_be:\n",
    "                                        destination_path = os.path.join(bids_directory, subject, ses, mode_should_be, file)\n",
    "                                        try:\n",
    "                                            #shutil.move(current_filepath, destination_path)\n",
    "                                            print(f\"File moved from {current_filepath} to {destination_path} successfully.\")\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"An error occurred file from {current_filepath} to {destination_path}: {e}\")\n",
    "                                elif file_end[0] == 'phase2':\n",
    "                                    mode_should_be='fmap'\n",
    "                                    if not mode == mode_should_be:\n",
    "                                        destination_path = os.path.join(bids_directory, subject, ses, mode_should_be, file)\n",
    "                                        try:\n",
    "                                            #shutil.move(current_filepath, destination_path)\n",
    "                                            print(f\"File moved from {current_filepath} to {destination_path} successfully.\")\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"An error occurred file from {current_filepath} to {destination_path}: {e}\")\n",
    "                                elif file_end[0] == 'phase1':\n",
    "                                    mode_should_be='fmap'\n",
    "                                    if not mode == mode_should_be:\n",
    "                                        destination_path = os.path.join(bids_directory, subject, ses, mode_should_be, file)\n",
    "                                        try:\n",
    "                                            #shutil.move(current_filepath, destination_path)\n",
    "                                            print(f\"File moved from {current_filepath} to {destination_path} successfully.\")\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"An error occurred file from {current_filepath} to {destination_path}: {e}\")\n",
    "                                elif file_end[0]== 'phasediff':\n",
    "                                    mode_should_be='fmap'\n",
    "                                    if not mode == mode_should_be:\n",
    "                                        destination_path = os.path.join(bids_directory, subject, ses, mode_should_be, file)\n",
    "                                        try:\n",
    "                                            #shutil.move(current_filepath, destination_path)\n",
    "                                            print(f\"File moved from {current_filepath} to {destination_path} successfully.\")\n",
    "                                        except Exception as e:\n",
    "                                            print(f\"An error occurred file from {current_filepath} to {destination_path}: {e}\")\n",
    "                                else: \n",
    "                                    print(f\"MISSING MODE:-- file_end[0] is {file_end[0]} \\n {current_filepath}: \")\n",
    "                                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "############ Make sure all JSONS are valid and UTF-8 Encoded #############\n",
    "\n",
    "\n",
    "import os\n",
    "import json\n",
    "\n",
    "bids_directory = \"/projects/f_ah1491_1/open_data/NAPLS3/bids_problem\"\n",
    "\n",
    "\n",
    "def validate_json(file_path):\n",
    "    try:\n",
    "        with open(file_path, 'r', encoding='utf-8') as f:\n",
    "            json.load(f)\n",
    "        #print(f\"Valid JSON file: {file_path}\")\n",
    "    except UnicodeDecodeError:\n",
    "        print(f\"Encoding error: {file_path} is not UTF-8 encoded.\")\n",
    "        try:\n",
    "            encode_to_utf8(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to encode {file_path} to UTF-8: {e}\\n\\n\")\n",
    "    except json.JSONDecodeError:\n",
    "        print(f\"Invalid JSON file: {file_path}\")\n",
    "\n",
    "def encode_to_utf8(file_path):\n",
    "    # Attempt to read the file with a fallback encoding\n",
    "    fallback_encodings = ['ISO-8859-1', 'latin1', 'cp1252']  # Add other encodings if necessary\n",
    "    for encoding in fallback_encodings:\n",
    "        try:\n",
    "            with open(file_path, 'r', encoding=encoding) as f:\n",
    "                content = f.read()\n",
    "            with open(file_path, 'w', encoding='utf-8') as f:\n",
    "                f.write(content)\n",
    "            print(f\"Successfully re-encoded {file_path} to UTF-8 from {encoding}.\")\n",
    "            return\n",
    "        except UnicodeDecodeError:\n",
    "            continue\n",
    "    raise UnicodeDecodeError(f\"Unable to decode {file_path} with fallback encodings.\")\n",
    "\n",
    "def find_and_validate_json_files(directory):\n",
    "    for root, _, files in os.walk(directory):\n",
    "        for file in files:\n",
    "            if file.endswith('.json'):\n",
    "                file_path = os.path.join(root, file)\n",
    "                validate_json(file_path)\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    find_and_validate_json_files(bids_directory)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### Adding or updating specific parts of the JSON metadata\n",
    "\n",
    "bids_directory = '/home/kj537/_f_ah1491_1/open_data/NAPLS3/bidata'\n",
    "layout = index_bids_directory(bids_directory)\n",
    "rm_list = []\n",
    "skip_files = ['dataset_description.json', 'participants.tsv', 'task-rest_bold.json']\n",
    "\n",
    "# Walk through the source_directory files\n",
    "for dirpath, dirnames, filenames in os.walk(bids_directory):\n",
    "    # Extract the first level subdirectory (subject id & session date)\n",
    "    relative_path = os.path.relpath(dirpath, source_images)\n",
    "    first_subdir = relative_path.split(os.sep)[0] if os.sep in relative_path else \"\"\n",
    "    # Go through files\n",
    "    for filename in filenames:\n",
    "        if filename.endswith('.json') and filename not in skip_files: #Extract the files\n",
    "            json_path = os.path.join(dirpath, filename)\n",
    "            nii_path = json_path.replace('.json','.nii.gz')\n",
    "            # Look for PhaseEncodingDirection element\n",
    "            ped = get_element('PhaseEncodingDirection', json_path)  # Look for 'PhaseEncodingDirection' in phasediff\n",
    "            allowed_ped = [ \"i\", \"i-\", \"j\", \"j-\", \"k\", \"k-\"]\n",
    "\n",
    "            # If it isn't there, add it\n",
    "            if not ped:\n",
    "                if 'dir-PA' in filename:\n",
    "                    update_json_key(json_path, 'PhaseEncodingDirection', 'j')\n",
    "                    print(f'Added PhaseEncodingDirection to {filename}')\n",
    "                elif 'dir-AP' in filename:\n",
    "                    update_json_key(json_path, 'PhaseEncodingDirection', 'j-')\n",
    "                    print(f'Added PhaseEncodingDirection to {filename}')\n",
    "                    \n",
    "            #If PhaseEncodingDirection there but not valid\n",
    "            elif ped not in allowed_ped:\n",
    "                if 'dir-PA' in filename:\n",
    "                    update_json_key(json_path, 'PhaseEncodingDirection', 'j')\n",
    "                elif 'dir-AP' in filename:\n",
    "                    update_json_key(json_path, 'PhaseEncodingDirection', 'j-')\n",
    "                \n",
    "            # Check if slicetiming is in seconds or milliseconds by comparing SliceTiming & RepetitionTime\n",
    "            st = get_element('SliceTiming', json_path)\n",
    "            \n",
    "            nifti_img = nib.load(nii_path)\n",
    "            header = nifti_img.header\n",
    "            # Access Repetition Time (TR) from 'pixdim' field\n",
    "            try:\n",
    "                tr = header.get_zooms()[-1]  # TR is usually the 4th element of pixdim\n",
    "            except Exception as e: \n",
    "                print(f\"An error occurred: {e}\\n {header.get_zooms()}\")\n",
    "    \n",
    "            if st:\n",
    "                if tr:\n",
    "                    print(f'tr is {tr}')\n",
    "                    #print(f'Sum of slicetimings is: {st}')\n",
    "                    scaled_numbers, factor = scale_SliceTiming(st)\n",
    "                    print(f'Scaled list by {factor} --> {scaled_numbers}\\n\\n\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (env)",
   "language": "python",
   "name": "env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
